# Home_Sales
Graded project for Module 22 Challenge
Using PySpark to run SQL queries directly in the Jupyter Notebook. I learned how to import the CSV file, create a temporary views and run queries. Also, I learned how to cache the Temp View and compare the impact of using a cached version to return queries faster. Finally, I use Parquet to partition and use the dataset.